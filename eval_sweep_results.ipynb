{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Diagnostic Sweep Evaluation: Multi-Critic with Fixes\n\nEvaluate multi-critic unlearning with gradient fixes\n\n**Date:** November 8, 2025\n\n**Configurations:**\n1. Lambda=10, balance=none\n2. Lambda=10, balance=ema_ratio\n3. Lambda=5, balance=none\n4. Lambda=5, balance=ema_ratio\n\n**All configs use:**\n- Feature-space MMD (gamma=0.1)\n- Matched unseen loader\n- Fixed gradient tracking\n- 30 epochs\n\n**Comparison:**\n- Baseline: AUC = 0.951\n- Retrain floor: AUC = 0.864\n- Target band: [0.834, 0.894]\n- Previous multi-critic (lambda=1, no fixes): AUC = 0.995 (FAILED)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from vae import VAE\n",
    "from attacker import MLPAttacker, extract_vae_features, build_attack_features\n",
    "from utils import set_global_seed\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/adata_processed.h5ad\"\n",
    "SPLIT_PATH = \"outputs/p1/split_structured.json\"\n",
    "\n",
    "CONFIGS = [\n",
    "    {\n",
    "        'name': 'Lambda=10, No Balance',\n",
    "        'short_name': 'lambda10_nobalance',\n",
    "        'checkpoint': 'outputs/p2/sweep_lambda10_nobalance/best_model.pt',\n",
    "        'lambda': 10,\n",
    "        'balance': 'none'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lambda=10, EMA Balance',\n",
    "        'short_name': 'lambda10_ema',\n",
    "        'checkpoint': 'outputs/p2/sweep_lambda10_ema/best_model.pt',\n",
    "        'lambda': 10,\n",
    "        'balance': 'ema_ratio'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lambda=5, No Balance',\n",
    "        'short_name': 'lambda5_nobalance',\n",
    "        'checkpoint': 'outputs/p2/sweep_lambda5_nobalance/best_model.pt',\n",
    "        'lambda': 5,\n",
    "        'balance': 'none'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lambda=5, EMA Balance',\n",
    "        'short_name': 'lambda5_ema',\n",
    "        'checkpoint': 'outputs/p2/sweep_lambda5_ema/best_model.pt',\n",
    "        'lambda': 5,\n",
    "        'balance': 'ema_ratio'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Evaluating configurations:\")\n",
    "for i, cfg in enumerate(CONFIGS, 1):\n",
    "    print(f\"{i}. {cfg['name']}\")\n",
    "    print(f\"   Checkpoint: {cfg['checkpoint']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(DATA_PATH)\n",
    "print(f\"Data shape: {adata.shape}\")\n",
    "\n",
    "with open(SPLIT_PATH, 'r') as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "forget_indices = np.array(splits['forget_indices'])\n",
    "retain_indices = np.array(splits['retain_indices'])\n",
    "unseen_indices = np.array(splits['unseen_indices'])\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  Forget: {len(forget_indices)}\")\n",
    "print(f\"  Retain: {len(retain_indices)}\")\n",
    "print(f\"  Unseen: {len(unseen_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataset(vae, adata, indices, device, batch_size=256):\n",
    "    \"\"\"Extract VAE features for attacker training.\"\"\"\n",
    "    vae.eval()\n",
    "    all_features = []\n",
    "    \n",
    "    for i in range(0, len(indices), batch_size):\n",
    "        batch_idx = indices[i:i+batch_size]\n",
    "        X = torch.FloatTensor(\n",
    "            adata.X[batch_idx].toarray() if hasattr(adata.X[batch_idx], 'toarray') \n",
    "            else adata.X[batch_idx]\n",
    "        ).to(device)\n",
    "        library_size = torch.FloatTensor(X.sum(dim=1, keepdim=True)).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            vae_feats = extract_vae_features(vae, X, library_size, device)\n",
    "            attack_feats = build_attack_features(vae_feats)\n",
    "            all_features.append(attack_feats.cpu())\n",
    "    \n",
    "    return torch.cat(all_features, dim=0)\n",
    "\n",
    "def train_attacker(pos_features, neg_features, input_dim, device, epochs=100, lr=0.001, verbose=True):\n",
    "    \"\"\"Train attacker to distinguish positive (1) from negative (0).\"\"\"\n",
    "    # Create dataset\n",
    "    pos_labels = torch.ones(len(pos_features), 1)\n",
    "    neg_labels = torch.zeros(len(neg_features), 1)\n",
    "    \n",
    "    X = torch.cat([pos_features, neg_features], dim=0)\n",
    "    y = torch.cat([pos_labels, neg_labels], dim=0)\n",
    "    \n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "    \n",
    "    # Initialize attacker\n",
    "    attacker = MLPAttacker(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=[256, 256],\n",
    "        dropout=0.3,\n",
    "        use_spectral_norm=True\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(attacker.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train\n",
    "    attacker.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = attacker(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if verbose and (epoch + 1) % 20 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(loader):.4f}\")\n",
    "    \n",
    "    attacker.eval()\n",
    "    return attacker\n",
    "\n",
    "def evaluate_binary(attacker, pos_features, neg_features, device):\n",
    "    \"\"\"Evaluate attacker on binary classification task.\"\"\"\n",
    "    attacker.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pos_logits = attacker(pos_features.to(device)).cpu().numpy()\n",
    "        neg_logits = attacker(neg_features.to(device)).cpu().numpy()\n",
    "    \n",
    "    pos_scores = torch.sigmoid(torch.FloatTensor(pos_logits)).numpy()\n",
    "    neg_scores = torch.sigmoid(torch.FloatTensor(neg_logits)).numpy()\n",
    "    \n",
    "    y_true = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
    "    y_score = np.concatenate([pos_scores, neg_scores])\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    \n",
    "    return auc, fpr, tpr\n",
    "\n",
    "def tpr_at_fpr(fpr, tpr, target_fpr):\n",
    "    \"\"\"Get TPR at target FPR.\"\"\"\n",
    "    idx = np.where(fpr <= target_fpr)[0]\n",
    "    if len(idx) == 0:\n",
    "        return 0.0\n",
    "    return tpr[idx[-1]]\n",
    "\n",
    "print(\"Helper functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate All Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i, cfg in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Config {i}/4: {cfg['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load VAE\n",
    "    print(f\"\\nLoading checkpoint: {cfg['checkpoint']}\")\n",
    "    checkpoint = torch.load(cfg['checkpoint'], map_location=device)\n",
    "    \n",
    "    vae = VAE(\n",
    "        input_dim=adata.n_vars,\n",
    "        latent_dim=32,\n",
    "        hidden_dims=[1024, 512, 128],\n",
    "        likelihood='nb',\n",
    "        dropout=0.1,\n",
    "        use_layer_norm=True\n",
    "    ).to(device)\n",
    "    \n",
    "    vae.load_state_dict(checkpoint['vae_state_dict'])\n",
    "    vae.eval()\n",
    "    \n",
    "    print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"  EMA privacy: {checkpoint.get('ema_privacy', 'N/A')}\")\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"\\nExtracting features...\")\n",
    "    forget_features = create_feature_dataset(vae, adata, forget_indices, device)\n",
    "    retain_features = create_feature_dataset(vae, adata, retain_indices, device)\n",
    "    unseen_features = create_feature_dataset(vae, adata, unseen_indices, device)\n",
    "    \n",
    "    input_dim = forget_features.shape[1]\n",
    "    print(f\"  Feature dim: {input_dim}\")\n",
    "    \n",
    "    # Train post-hoc attacker\n",
    "    print(\"\\nTraining post-hoc attacker...\")\n",
    "    neg_features = torch.cat([retain_features, unseen_features], dim=0)\n",
    "    attacker = train_attacker(forget_features, neg_features, input_dim, device, epochs=100, verbose=True)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\nEvaluating...\")\n",
    "    auc_f_vs_u, fpr_f_vs_u, tpr_f_vs_u = evaluate_binary(attacker, forget_features, unseen_features, device)\n",
    "    auc_f_vs_r, fpr_f_vs_r, tpr_f_vs_r = evaluate_binary(attacker, forget_features, retain_features, device)\n",
    "    auc_two_neg = (auc_f_vs_u + auc_f_vs_r) / 2\n",
    "    \n",
    "    # TPR at low FPR\n",
    "    tpr_1pct_u = tpr_at_fpr(fpr_f_vs_u, tpr_f_vs_u, 0.01)\n",
    "    tpr_01pct_u = tpr_at_fpr(fpr_f_vs_u, tpr_f_vs_u, 0.001)\n",
    "    tpr_1pct_r = tpr_at_fpr(fpr_f_vs_r, tpr_f_vs_r, 0.01)\n",
    "    tpr_01pct_r = tpr_at_fpr(fpr_f_vs_r, tpr_f_vs_r, 0.001)\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'config': cfg['name'],\n",
    "        'short_name': cfg['short_name'],\n",
    "        'lambda': cfg['lambda'],\n",
    "        'balance': cfg['balance'],\n",
    "        'checkpoint': cfg['checkpoint'],\n",
    "        'auc_f_vs_u': float(auc_f_vs_u),\n",
    "        'auc_f_vs_r': float(auc_f_vs_r),\n",
    "        'auc_two_negative': float(auc_two_neg),\n",
    "        'fpr_f_vs_u': fpr_f_vs_u,\n",
    "        'tpr_f_vs_u': tpr_f_vs_u,\n",
    "        'fpr_f_vs_r': fpr_f_vs_r,\n",
    "        'tpr_f_vs_r': tpr_f_vs_r,\n",
    "        'tpr_1pct_fpr_u': float(tpr_1pct_u),\n",
    "        'tpr_01pct_fpr_u': float(tpr_01pct_u),\n",
    "        'tpr_1pct_fpr_r': float(tpr_1pct_r),\n",
    "        'tpr_01pct_fpr_r': float(tpr_01pct_r),\n",
    "        'gap_to_floor': float(auc_two_neg - 0.864),\n",
    "        'within_target': bool(0.834 <= auc_two_neg <= 0.894)\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"RESULTS: {cfg['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"AUC (F vs U):        {auc_f_vs_u:.4f}\")\n",
    "    print(f\"AUC (F vs R):        {auc_f_vs_r:.4f}\")\n",
    "    print(f\"AUC (Two-Negative):  {auc_two_neg:.4f}\")\n",
    "    print(f\"\\nTPR at Low FPR (F vs U):\")\n",
    "    print(f\"  TPR @ 1% FPR:      {tpr_1pct_u:.4f}\")\n",
    "    print(f\"  TPR @ 0.1% FPR:    {tpr_01pct_u:.4f}\")\n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"  Retrain Floor:     0.864\")\n",
    "    print(f\"  Target Band:       [0.834, 0.894]\")\n",
    "    print(f\"  Gap to floor:      {auc_two_neg - 0.864:+.3f}\")\n",
    "    print(f\"  Within target:     {'YES' if result['within_target'] else 'NO'}\")\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(\"ALL EVALUATIONS COMPLETE\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "df = pd.DataFrame([{\n",
    "    'Config': r['config'],\n",
    "    'Lambda': r['lambda'],\n",
    "    'Balance': r['balance'],\n",
    "    'AUC (Two-Neg)': f\"{r['auc_two_negative']:.4f}\",\n",
    "    'Gap to Floor': f\"{r['gap_to_floor']:+.3f}\",\n",
    "    'Within Target': 'YES' if r['within_target'] else 'NO',\n",
    "    'TPR@1%FPR (U)': f\"{r['tpr_1pct_fpr_u']:.3f}\"\n",
    "} for r in results])\n",
    "\n",
    "print(\"\\n=== SWEEP RESULTS COMPARISON ===\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"\\nBenchmarks:\")\n",
    "print(\"  Baseline:           0.951\")\n",
    "print(\"  Multi-Critic (old): 0.995 (FAILED - no gradient fixes)\")\n",
    "print(\"  Retrain Floor:      0.864\")\n",
    "print(\"  Target Band:        [0.834, 0.894]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves - F vs U\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "for i, (result, color) in enumerate(zip(results, colors)):\n",
    "    ax.plot(result['fpr_f_vs_u'], result['tpr_f_vs_u'], \n",
    "            color=color, linewidth=2, \n",
    "            label=f\"{result['config']} (AUC={result['auc_f_vs_u']:.3f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
    "ax.axhline(y=0.864, color='orange', linestyle='--', alpha=0.5, linewidth=2, label='Retrain Floor')\n",
    "ax.fill_between([0, 1], 0.834, 0.894, alpha=0.1, color='green', label='Target Band')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves: Forget vs Unseen (Post-Hoc Attacker)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/p2/sweep_roc_f_vs_u.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: outputs/p2/sweep_roc_f_vs_u.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed ROC curves - Low FPR region\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "for i, (result, color) in enumerate(zip(results, colors)):\n",
    "    ax.plot(result['fpr_f_vs_u'], result['tpr_f_vs_u'], \n",
    "            color=color, linewidth=2, \n",
    "            label=f\"{result['config']}\")\n",
    "\n",
    "ax.axvline(x=0.01, color='orange', linestyle=':', alpha=0.5, label='1% FPR')\n",
    "ax.axvline(x=0.001, color='purple', linestyle=':', alpha=0.5, label='0.1% FPR')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves: Low FPR Region', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 0.05])\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/p2/sweep_roc_zoomed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: outputs/p2/sweep_roc_zoomed.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# AUC comparison\n",
    "configs_short = [r['short_name'] for r in results]\n",
    "aucs = [r['auc_two_negative'] for r in results]\n",
    "\n",
    "axes[0].bar(range(len(aucs)), aucs, color=colors, alpha=0.7)\n",
    "axes[0].axhline(y=0.864, color='orange', linestyle='--', linewidth=2, label='Retrain Floor')\n",
    "axes[0].axhspan(0.834, 0.894, alpha=0.1, color='green', label='Target Band')\n",
    "axes[0].set_ylabel('AUC (Two-Negative)', fontsize=12)\n",
    "axes[0].set_title('Post-Hoc Privacy (Lower = Better)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticks(range(len(configs_short)))\n",
    "axes[0].set_xticklabels(configs_short, rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Gap to floor\n",
    "gaps = [r['gap_to_floor'] for r in results]\n",
    "bar_colors = ['green' if abs(g) < 0.05 else 'orange' if abs(g) < 0.1 else 'red' for g in gaps]\n",
    "\n",
    "axes[1].bar(range(len(gaps)), gaps, color=bar_colors, alpha=0.7)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].axhspan(-0.03, 0.03, alpha=0.1, color='green', label='Success Zone (Â±0.03)')\n",
    "axes[1].set_ylabel('Gap to Retrain Floor', fontsize=12)\n",
    "axes[1].set_title('Distance from Target (Closer to 0 = Better)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(range(len(configs_short)))\n",
    "axes[1].set_xticklabels(configs_short, rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/p2/sweep_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: outputs/p2/sweep_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save individual results\nfor result in results:\n    # Remove numpy arrays for JSON serialization\n    result_json = {k: v for k, v in result.items() if not isinstance(v, np.ndarray)}\n    \n    output_path = Path(f\"outputs/p2/{result['short_name']}_results.json\")\n    with open(output_path, 'w') as f:\n        json.dump(result_json, f, indent=2)\n    print(f\"Saved: {output_path}\")\n\n# Save summary\nsummary = {\n    'evaluation_date': '2025-11-08',\n    'method': 'multi_critic_sweep_gradient_fixes',\n    'configurations': len(results),\n    'benchmarks': {\n        'baseline': 0.951,\n        'multicritic_old_lambda1': 0.995,\n        'retrain_floor': 0.864,\n        'target_lower': 0.834,\n        'target_upper': 0.894\n    },\n    'results': [{k: v for k, v in r.items() if not isinstance(v, np.ndarray)} for r in results],\n    'best_config': min(results, key=lambda x: abs(x['gap_to_floor']))['config'],\n    'best_auc': min(results, key=lambda x: abs(x['gap_to_floor']))['auc_two_negative']\n}\n\nsummary_path = Path('outputs/p2/sweep_summary.json')\nwith open(summary_path, 'w') as f:\n    json.dump(summary, f, indent=2)\n\nprint(f\"\\nSummary saved: {summary_path}\")\nprint(\"\\n=== EVALUATION COMPLETE ===\")\nprint(f\"Best config: {summary['best_config']}\")\nprint(f\"Best AUC: {summary['best_auc']:.4f}\")\nprint(f\"Gap to floor: {min(results, key=lambda x: abs(x['gap_to_floor']))['gap_to_floor']:+.3f}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}