{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 21. Selective Synaptic Dampening (SSD) Experiments\n",
    "\n",
    "SSD (Foster et al., AAAI 2024) dampens parameters proportional to their Fisher importance\n",
    "for the forget set relative to the retain set. Unlike our original Fisher scrubbing\n",
    "(gradient ascent + Fisher weighting), SSD uses multiplicative dampening:\n",
    "theta *= (1 - alpha * F_forget / F_retain).\n",
    "\n",
    "We test SSD on PBMC structured forget set with 3 seeds and evaluate\n",
    "using the canonical fresh-attacker methodology (NB03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from train_ssd import train_ssd\n",
    "\n",
    "DATA_PATH = '../data/adata_processed.h5ad'\n",
    "SPLIT_PATH = '../outputs/p1/split_structured.json'\n",
    "BASELINE_CKPT = '../outputs/p1/baseline/best_model.pt'\n",
    "OUTPUT_BASE = Path('../outputs/p2/ssd')\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Train SSD with 3 Seeds\n",
    "\n",
    "Hyperparameters:\n",
    "- alpha=1.0 (full dampening strength)\n",
    "- threshold=0.0 (dampen all parameters)\n",
    "- damping=1e-5 (Fisher numerical stability)\n",
    "- 10 epochs retain fine-tuning, lr=1e-4, patience=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SSD alpha=1.0, seed=42\n",
      "============================================================\n",
      "Data: torch.Size([33088, 2000]), Forget: 30, Retain: 28094, Device: cpu\n",
      "Computing Fisher on forget set...\n",
      "Computing Fisher on retain set...\n",
      "Applying SSD dampening (alpha=1.0, threshold=0.0)...\n",
      "  Dampened 100.0% of parameters\n",
      "  Mean dampening magnitude: 0.2798\n",
      "Fine-tuning on retain set (10 epochs, lr=0.0001)...\n",
      "  Epoch 1: train=366.35, val=358.17\n",
      "  Epoch 5: train=365.82, val=357.98\n",
      "  Epoch 10: train=365.51, val=357.58\n",
      "Saved to ../outputs/p2/ssd/alpha1.0_seed42/best_model.pt\n",
      "Done in 82.9s\n",
      "\n",
      "============================================================\n",
      "SSD alpha=1.0, seed=123\n",
      "============================================================\n",
      "Data: torch.Size([33088, 2000]), Forget: 30, Retain: 28094, Device: cpu\n",
      "Computing Fisher on forget set...\n",
      "Computing Fisher on retain set...\n",
      "Applying SSD dampening (alpha=1.0, threshold=0.0)...\n",
      "  Dampened 100.0% of parameters\n",
      "  Mean dampening magnitude: 0.2800\n",
      "Fine-tuning on retain set (10 epochs, lr=0.0001)...\n",
      "  Epoch 1: train=366.34, val=361.82\n",
      "  Epoch 5: train=365.71, val=361.59\n",
      "  Epoch 10: train=365.41, val=361.22\n",
      "Saved to ../outputs/p2/ssd/alpha1.0_seed123/best_model.pt\n",
      "Done in 81.2s\n",
      "\n",
      "============================================================\n",
      "SSD alpha=1.0, seed=456\n",
      "============================================================\n",
      "Data: torch.Size([33088, 2000]), Forget: 30, Retain: 28094, Device: cpu\n",
      "Computing Fisher on forget set...\n",
      "Computing Fisher on retain set...\n",
      "Applying SSD dampening (alpha=1.0, threshold=0.0)...\n",
      "  Dampened 100.0% of parameters\n",
      "  Mean dampening magnitude: 0.2797\n",
      "Fine-tuning on retain set (10 epochs, lr=0.0001)...\n",
      "  Epoch 1: train=366.62, val=362.90\n",
      "  Epoch 5: train=365.77, val=362.05\n",
      "  Epoch 10: train=365.51, val=361.82\n",
      "Saved to ../outputs/p2/ssd/alpha1.0_seed456/best_model.pt\n",
      "Done in 79.8s\n",
      "\n",
      "============================================================\n",
      "SSD alpha=0.5, seed=42\n",
      "============================================================\n",
      "Data: torch.Size([33088, 2000]), Forget: 30, Retain: 28094, Device: cpu\n",
      "Computing Fisher on forget set...\n",
      "Computing Fisher on retain set...\n",
      "Applying SSD dampening (alpha=0.5, threshold=0.0)...\n",
      "  Dampened 100.0% of parameters\n",
      "  Mean dampening magnitude: 0.1399\n",
      "Fine-tuning on retain set (10 epochs, lr=0.0001)...\n",
      "  Epoch 1: train=366.00, val=358.08\n",
      "  Epoch 5: train=365.73, val=357.96\n",
      "  Epoch 10: train=365.46, val=357.57\n",
      "Saved to ../outputs/p2/ssd/alpha0.5_seed42/best_model.pt\n",
      "Done in 79.4s\n",
      "\n",
      "============================================================\n",
      "SSD alpha=5.0, seed=42\n",
      "============================================================\n",
      "Data: torch.Size([33088, 2000]), Forget: 30, Retain: 28094, Device: cpu\n",
      "Computing Fisher on forget set...\n",
      "Computing Fisher on retain set...\n",
      "Applying SSD dampening (alpha=5.0, threshold=0.0)...\n",
      "  Dampened 100.0% of parameters\n",
      "  Mean dampening magnitude: 1.3990\n",
      "Fine-tuning on retain set (10 epochs, lr=0.0001)...\n",
      "  Epoch 1: train=376.90, val=361.62\n",
      "  Epoch 5: train=367.02, val=358.68\n",
      "  Epoch 10: train=366.19, val=358.05\n",
      "Saved to ../outputs/p2/ssd/alpha5.0_seed42/best_model.pt\n",
      "Done in 81.4s\n",
      "\n",
      "All training complete. 5 checkpoints saved.\n"
     ]
    }
   ],
   "source": [
    "SEEDS = [42, 123, 456]\n",
    "ALPHAS = [0.5, 1.0, 5.0]  # Sweep dampening strength\n",
    "\n",
    "results = {}\n",
    "\n",
    "# First: train with default alpha=1.0 across seeds\n",
    "for seed in SEEDS:\n",
    "    out_dir = OUTPUT_BASE / f'alpha1.0_seed{seed}'\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'SSD alpha=1.0, seed={seed}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    ckpt_path = train_ssd(\n",
    "        baseline_checkpoint=BASELINE_CKPT,\n",
    "        data_path=DATA_PATH,\n",
    "        split_path=SPLIT_PATH,\n",
    "        output_dir=str(out_dir),\n",
    "        alpha=1.0,\n",
    "        threshold=0.0,\n",
    "        damping=1e-5,\n",
    "        finetune_epochs=10,\n",
    "        finetune_lr=1e-4,\n",
    "        patience=10,\n",
    "        batch_size=256,\n",
    "        seed=seed,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    results[f'alpha1.0_seed{seed}'] = {'path': str(ckpt_path), 'time': elapsed}\n",
    "    print(f'Done in {elapsed:.1f}s')\n",
    "\n",
    "# Alpha sweep with seed=42\n",
    "for alpha in [0.5, 5.0]:\n",
    "    out_dir = OUTPUT_BASE / f'alpha{alpha}_seed42'\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'SSD alpha={alpha}, seed=42')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    ckpt_path = train_ssd(\n",
    "        baseline_checkpoint=BASELINE_CKPT,\n",
    "        data_path=DATA_PATH,\n",
    "        split_path=SPLIT_PATH,\n",
    "        output_dir=str(out_dir),\n",
    "        alpha=alpha,\n",
    "        threshold=0.0,\n",
    "        damping=1e-5,\n",
    "        finetune_epochs=10,\n",
    "        finetune_lr=1e-4,\n",
    "        patience=10,\n",
    "        batch_size=256,\n",
    "        seed=42,\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    results[f'alpha{alpha}_seed42'] = {'path': str(ckpt_path), 'time': elapsed}\n",
    "    print(f'Done in {elapsed:.1f}s')\n",
    "\n",
    "print(f'\\nAll training complete. {len(results)} checkpoints saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Evaluate with Canonical Fresh Attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget: 30, Matched neg: 194\n",
      "Training fresh attacker on baseline F vs matched:\n",
      "  Samples: 224 (30 forget + 194 matched)\n",
      "  Features: 70 dims\n",
      "  Train: 179, Test: 45\n",
      "  Baseline AUC (F vs matched, full set): 0.7792\n",
      "  (Canonical NB03 value: ~0.769)\n"
     ]
    }
   ],
   "source": [
    "# Use eval_multiseed infrastructure for canonical evaluation\n",
    "sys.path.insert(0, '../scripts')\n",
    "from eval_multiseed import (\n",
    "    load_vae_model, train_fresh_attacker, evaluate_privacy,\n",
    "    evaluate_utility, get_retain_latent_codes, MARKER_GENES\n",
    ")\n",
    "import scanpy as sc\n",
    "\n",
    "# Load data\n",
    "adata = sc.read_h5ad(DATA_PATH)\n",
    "X = torch.tensor(\n",
    "    adata.X.toarray() if hasattr(adata.X, 'toarray') else adata.X,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "with open(SPLIT_PATH) as f:\n",
    "    split = json.load(f)\n",
    "forget_idx = split['forget_indices']\n",
    "retain_idx = split['retain_indices']\n",
    "unseen_idx = split['unseen_indices']\n",
    "\n",
    "# Load matched negatives\n",
    "with open('../outputs/p1.5/s1_matched_negatives.json') as f:\n",
    "    matched_data = json.load(f)\n",
    "matched_neg_idx = matched_data['matched_indices']\n",
    "\n",
    "print(f'Forget: {len(forget_idx)}, Matched neg: {len(matched_neg_idx)}')\n",
    "\n",
    "# Holdout data for utility\n",
    "X_holdout = X[unseen_idx]\n",
    "lib_holdout = X_holdout.sum(dim=1, keepdim=True)\n",
    "labels_holdout = adata.obs['leiden'].values[unseen_idx]\n",
    "\n",
    "# Marker gene indices\n",
    "gene_names = list(adata.var_names)\n",
    "marker_idx = [gene_names.index(g) for g in MARKER_GENES if g in gene_names]\n",
    "marker_names = [g for g in MARKER_GENES if g in gene_names]\n",
    "\n",
    "# Train fresh attacker on baseline\n",
    "baseline_model, _ = load_vae_model(BASELINE_CKPT)\n",
    "attacker = train_fresh_attacker(\n",
    "    baseline_model, adata, forget_idx, matched_neg_idx, retain_idx, seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating alpha1.0_seed42...\n",
      "  AUC=0.724, Advantage=0.448, ELBO=363.9, Marker r=0.832\n",
      "\n",
      "Evaluating alpha1.0_seed123...\n",
      "  AUC=0.726, Advantage=0.452, ELBO=363.8, Marker r=0.831\n",
      "\n",
      "Evaluating alpha1.0_seed456...\n",
      "  AUC=0.725, Advantage=0.451, ELBO=363.9, Marker r=0.831\n",
      "\n",
      "Evaluating alpha0.5_seed42...\n",
      "  AUC=0.730, Advantage=0.460, ELBO=363.9, Marker r=0.832\n",
      "\n",
      "Evaluating alpha5.0_seed42...\n",
      "  AUC=0.634, Advantage=0.268, ELBO=364.3, Marker r=0.831\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all checkpoints\n",
    "eval_results = {}\n",
    "\n",
    "for name, info in results.items():\n",
    "    ckpt_path = info['path']\n",
    "    print(f'\\nEvaluating {name}...')\n",
    "    \n",
    "    model, config = load_vae_model(ckpt_path)\n",
    "    \n",
    "    privacy = evaluate_privacy(\n",
    "        model, attacker, adata, forget_idx, matched_neg_idx, retain_idx\n",
    "    )\n",
    "    utility = evaluate_utility(\n",
    "        model, X_holdout, labels_holdout, marker_idx, gene_names\n",
    "    )\n",
    "    \n",
    "    eval_results[name] = {\n",
    "        'privacy': privacy,\n",
    "        'utility': utility,\n",
    "        'training_time': info['time'],\n",
    "    }\n",
    "    \n",
    "    print(f'  AUC={privacy[\"mlp_auc\"]:.3f}, '\n",
    "          f'Advantage={privacy[\"mlp_advantage\"]:.3f}, '\n",
    "          f'ELBO={utility[\"elbo\"]:.1f}, '\n",
    "          f'Marker r={utility[\"marker_r\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD Results (alpha=1.0, 3 seeds):\n",
      "  AUC: 0.725 +/- 0.001\n",
      "  Advantage: 0.450 +/- 0.002\n",
      "\n",
      "Alpha sweep (seed=42):\n",
      "Alpha           AUC  Advantage   Marker r     ELBO\n",
      "--------------------------------------------------\n",
      "0.5           0.730      0.460      0.832    363.9\n",
      "1.0           0.724      0.448      0.832    363.9\n",
      "5.0           0.634      0.268      0.831    364.3\n",
      "\n",
      "Reference: Retrain AUC=0.523, Advantage=0.046\n",
      "Reference: Baseline AUC=0.783, Advantage=0.565\n"
     ]
    }
   ],
   "source": [
    "# Aggregate alpha=1.0 seeds\n",
    "alpha1_aucs = []\n",
    "alpha1_advantages = []\n",
    "for seed in SEEDS:\n",
    "    key = f'alpha1.0_seed{seed}'\n",
    "    if key in eval_results:\n",
    "        alpha1_aucs.append(eval_results[key]['privacy']['mlp_auc'])\n",
    "        alpha1_advantages.append(eval_results[key]['privacy']['mlp_advantage'])\n",
    "\n",
    "print('SSD Results (alpha=1.0, 3 seeds):')\n",
    "print(f'  AUC: {np.mean(alpha1_aucs):.3f} +/- {np.std(alpha1_aucs):.3f}')\n",
    "print(f'  Advantage: {np.mean(alpha1_advantages):.3f} +/- {np.std(alpha1_advantages):.3f}')\n",
    "print()\n",
    "\n",
    "# Alpha sweep comparison\n",
    "print('Alpha sweep (seed=42):')\n",
    "print(f'{\"Alpha\":<10} {\"AUC\":>8} {\"Advantage\":>10} {\"Marker r\":>10} {\"ELBO\":>8}')\n",
    "print('-' * 50)\n",
    "for alpha in [0.5, 1.0, 5.0]:\n",
    "    key = f'alpha{alpha}_seed42'\n",
    "    if key in eval_results:\n",
    "        r = eval_results[key]\n",
    "        print(f'{alpha:<10.1f} {r[\"privacy\"][\"mlp_auc\"]:>8.3f} '\n",
    "              f'{r[\"privacy\"][\"mlp_advantage\"]:>10.3f} '\n",
    "              f'{r[\"utility\"][\"marker_r\"]:>10.3f} '\n",
    "              f'{r[\"utility\"][\"elbo\"]:>8.1f}')\n",
    "\n",
    "print()\n",
    "print('Reference: Retrain AUC=0.523, Advantage=0.046')\n",
    "print('Reference: Baseline AUC=0.783, Advantage=0.565')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../outputs/p2/ssd/ssd_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "output = {\n",
    "    'method': 'ssd',\n",
    "    'dataset': 'PBMC',\n",
    "    'forget_type': 'structured',\n",
    "    'seeds': SEEDS,\n",
    "    'alpha_sweep': [0.5, 1.0, 5.0],\n",
    "    'results': eval_results,\n",
    "    'summary': {\n",
    "        'alpha1.0': {\n",
    "            'mean_auc': float(np.mean(alpha1_aucs)),\n",
    "            'std_auc': float(np.std(alpha1_aucs)),\n",
    "            'mean_advantage': float(np.mean(alpha1_advantages)),\n",
    "            'std_advantage': float(np.std(alpha1_advantages)),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTPUT_BASE / 'ssd_results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2, default=str)\n",
    "\n",
    "print(f'Saved to {OUTPUT_BASE / \"ssd_results.json\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat4243",
   "language": "python",
   "name": "stat4243"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
